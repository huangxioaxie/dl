{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c474713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jieba 汉语词性对照标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183f1c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\hys\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.544 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('上市', 1.437080435586), ('上线', 0.820694551317), ('奇迹', 0.775434839431), ('互联网', 0.712189275429), ('平台', 0.6244340485550001), ('企业', 0.422177218495), ('美国', 0.415659623166), ('问题', 0.39635135730800003)]\n",
      "上市 1.437080435586\n",
      "上线 0.820694551317\n",
      "奇迹 0.775434839431\n",
      "互联网 0.712189275429\n",
      "平台 0.6244340485550001\n",
      "企业 0.422177218495\n",
      "美国 0.415659623166\n",
      "问题 0.39635135730800003\n",
      "[('上市', 1.0), ('奇迹', 0.572687398431635), ('企业', 0.5710407272273452), ('互联网', 0.5692560484441649), ('上线', 0.23481844682115297), ('美国', 0.23481844682115297)]\n",
      "上市 1.0\n",
      "奇迹 0.572687398431635\n",
      "企业 0.5710407272273452\n",
      "互联网 0.5692560484441649\n",
      "上线 0.23481844682115297\n",
      "美国 0.23481844682115297\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import jieba.posseg as posg\n",
    "\n",
    "# 使用 jieba 进行词性切分，allowPOS 指定允许的词性，这里选择名词 n 和地名 ns\n",
    "sentence = u'''上线三年就成功上市,拼多多上演了互联网企业的上市奇迹,却也放大平台上存在的诸多问题，拼多多在美国上市。'''\n",
    "kw = jieba.analyse.extract_tags(sentence, topK=10, withWeight=True, allowPOS=('n', 'ns'))\n",
    "print(kw)\n",
    "for item in kw:\n",
    "    print(item[0], item[1])\n",
    "\n",
    "kw = jieba.analyse.textrank(sentence,topK=20,withWeight=True,allowPOS=('ns','n'))\n",
    "print(kw)\n",
    "for item in kw:\n",
    "    print(item[0],item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0e23d",
   "metadata": {},
   "source": [
    "# 词性标注\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b76fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n"
     ]
    }
   ],
   "source": [
    "words =posg.cut(\"我爱北京天安门\")\n",
    "for w in words:\n",
    "   print (w.word,w.flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec90486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thulac\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import jieba\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import jieba.posseg as posg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c321a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3908\n",
      "['的', '。', '是', ' ', '\\n', '日', '月', '.', '%', '\\u3000', '--', '?', '“', '”', '》', '－－', 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', \"ain't\", 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', \"aren't\", 'around', 'as', \"a's\", 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', 'came', 'can', 'cannot', 'cant', \"can't\", 'cause', 'causes', 'certain']\n"
     ]
    }
   ],
   "source": [
    "# 停词表\n",
    "\n",
    "def load_stop_word():\n",
    "    stop_word = ['的', '。', '是', ' ', '\\n', '日', '月', '.', '%','\\u3000']\n",
    "    stop_word_file = 'c:/data/stopwords'\n",
    "    stop_word_dirs = os.listdir(stop_word_file)\n",
    "    for textName in stop_word_dirs:\n",
    "        filename = stop_word_file + '/' + textName\n",
    "        with open(filename, 'r', encoding='utf-8') as file_object:\n",
    "            line = file_object.readline()\n",
    "            while line:\n",
    "                stop_word.append(line[0:-1])\n",
    "                line = file_object.readline()\n",
    "    return stop_word\n",
    "\n",
    "stop_word = load_stop_word()\n",
    "print(len(stop_word))\n",
    "print(stop_word[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea26a2d6",
   "metadata": {},
   "source": [
    "# jieba 分词\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03996bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('控制 训练 文章 数量 ', {'控制': 'v', '训练': 'vn', '文章': 'n', '数量': 'n'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#分词\n",
    " # 默认模式，分词的同时进行词性标注\n",
    "# thu = thulac.thulac(filt=True, seg_only=True)\n",
    "word_type = {}\n",
    "def cut_doc(doc):\n",
    "     # 默认模式，分词的同时进行词性标注\n",
    "    \n",
    "    words = posg.cut(doc)\n",
    "    words_in_doc = \"\"\n",
    "    for w in words:\n",
    "        # print(word)\n",
    "        if w.word in stop_word: continue\n",
    "        words_in_doc +=  w.word + \" \"\n",
    "        try:\n",
    "            old_flag = word_type[w.word]\n",
    "            if old_flag != w.flag:\n",
    "                print('一词多义')\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        word_type[w.word] = w.flag\n",
    "        \n",
    "    return words_in_doc\n",
    "\n",
    "words_in_doc = cut_doc(\"用来控制训练的文章数量\")\n",
    "words_in_doc,word_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ec1efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_doc = cut_doc('他作为学生代表参加了大会')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d322ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_doc = cut_doc('他是代表小李来参加大会的')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40d30ffc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m map1 \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmap1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b8cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
